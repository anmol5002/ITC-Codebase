{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy                                # Various libraries imported from tensorflow and keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/itc.DESKTOP-RF2G1DL/Desktop/cam2_training_lid/train/'            # training path needs to be specified where both bad and good images are present in folders\n",
    "valid_path = 'C:/Users/itc.DESKTOP-RF2G1DL/Desktop/cam2_training_lid/validation/'       # similarly validation images and test image path needs to be specified\n",
    "test_path = 'C:/Users/itc.DESKTOP-RF2G1DL/Desktop/cam2_training_lid/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_sizes=32\n",
    "save_after=20              # save model after this much epochs\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['bad', 'good'], batch_size=Batch_sizes)    # Photos are fed as a batch in training i.e. here 32 images are processed per batch\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['bad', 'good'], batch_size=Batch_sizes)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['bad', 'good'], batch_size=Batch_sizes,shuffle=False) # If (shuffle = False) then images are not shuffled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialised\n",
    "vgg16_model = keras.applications.vgg16.VGG16()               # VGG Model is imported which is available at default path i.e. ‘C:\\Users\\itc.DESKTOP-RF2G1DL\\______’ \n",
    "                                                             # If it is not available at default location this will automatically download (Time-consuming)\n",
    "vgg16_model.layers.pop()                                     # last layer of model is scrapped\n",
    "\n",
    "train_labels=train_batches.classes                           # Print number to be printed after training (Each class is given a number) Eg. (Bad:'0', Good:'1')\n",
    "\n",
    "model = Sequential()                                         # Model is defined as a sequential layer for development \n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "for layer in model.layers:                                   # All layers in initial model are not trained and hence layer.trainable = False\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))                    # Add our own layer where only 2 outputs are there (Train only this layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(Adam(lr=.05), loss='categorical_crossentropy', metrics=['accuracy'])                           #\n",
    "                                                                                                             #  Hyperparameters \n",
    "mc = keras.callbacks.ModelCheckpoint('cam2_lid{epoch:06d}.h5', save_weights_only=True, period=save_after)    #  More description in Notes\n",
    "                                                                                                             #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=157,validation_data=valid_batches, validation_steps=6, epochs=150, verbose=1,callbacks=[mc]) # Training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################## Training is complete and model saved ######################################################\n",
    "######### Some development tools available in appendix section #######################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
